{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "261dde76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mixins'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[194], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     Column, Integer, String, Text, ForeignKey, DateTime, Boolean, Enum, Index, Table, UniqueConstraint, JSON, Float, event, inspect\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m func\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmixins\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimestampMixin\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m relationship, declarative_base, Session\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_engine\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mixins'"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import (\n",
    "    Column, Integer, String, Text, ForeignKey, DateTime, Boolean, Enum, Index, Table, UniqueConstraint, JSON, Float, event, inspect\n",
    ")\n",
    "from sqlalchemy.sql import func\n",
    "from mixins import TimestampMixin\n",
    "from sqlalchemy.orm import relationship, declarative_base, Session\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.sql import func\n",
    "from datetime import datetime\n",
    "from sqlalchemy.dialects.postgresql import JSONB\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import boto3\n",
    "import enum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcda186",
   "metadata": {},
   "source": [
    "# Step 0. Imports & Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d21122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-21 14:00:55,055 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-09-21 14:00:55,055 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-21 14:00:55,056 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-09-21 14:00:55,056 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-21 14:00:55,057 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-09-21 14:00:55,057 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-09-21 14:00:55,058 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-09-21 14:00:55,058 INFO sqlalchemy.engine.Engine SELECT version();\n",
      "2025-09-21 14:00:55,058 INFO sqlalchemy.engine.Engine [generated in 0.00052s] {}\n",
      "✅ Connected to: PostgreSQL 14.18 (Homebrew) on aarch64-apple-darwin23.6.0, compiled by Apple clang version 16.0.0 (clang-1600.0.26.6), 64-bit\n",
      "2025-09-21 14:00:55,059 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "# from sqlalchemy import create_engine, text\n",
    "\n",
    "# # load the .env file\n",
    "# load_dotenv()\n",
    "\n",
    "# # get database url\n",
    "# DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "# engine = create_engine(DATABASE_URL, echo=True)\n",
    "\n",
    "# with engine.connect() as conn:\n",
    "#     result = conn.execute(text(\"SELECT version();\"))\n",
    "#     print(\"✅ Connected to:\", result.scalar())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e0172b",
   "metadata": {},
   "source": [
    "### CAUTION: SQLAlchemy’s in-memory registry.\n",
    "When you re-run your model definitions (class Project(Base) etc.), SQLAlchemy thinks you’re trying to define the same table again in the same Python session.\n",
    "\n",
    "Fixes:\n",
    "\n",
    "* Restart the kernel (clean slate).\n",
    "\n",
    "* Or run Base.metadata.clear() before re-defining models.\n",
    "\n",
    "* Or (not recommended for production, but useful in notebooks) add:    \n",
    "\n",
    "`__table_args__ = {\"extend_existing\": True}`    \n",
    "\n",
    "inside each model.    \n",
    "\n",
    "**Potential problems of 3rd option-- Silent overwrites**    \n",
    "\n",
    "If you redefine a model with different column definitions, SQLAlchemy will happily overwrite the in-memory Python mapping.    \n",
    "\n",
    "But the database table itself is unchanged — unless you drop/recreate or run a migration.    \n",
    "\n",
    "This can cause a mismatch: your Python code thinks a column exists (or has a new type), but the real Postgres table does not.    \n",
    "\n",
    "### My own suggestion:    \n",
    "#### During prototyping stage:         \n",
    "* use `__table_args__ = {\"extend_existing\": True}` for each model;\n",
    "    \n",
    "#### When your schema stabilizes and you’re preparing for AWS deployment:    \n",
    "1. Move your models into models.py (or a models/ package).\n",
    "\n",
    "        Delete __table_args__ = {\"extend_existing\": True} from each model.\n",
    "        Define Base = declarative_base() once at the top.\n",
    "\n",
    "2. Add Alembic to manage schema evolution:\n",
    "\n",
    "    `pip install alembic`    \n",
    "\n",
    "    `alembic init migrations`    \n",
    "\n",
    "* Configure alembic.ini with your DATABASE_URL.   \n",
    "\n",
    "* In env.py, set target_metadata = Base.metadata.\n",
    "\n",
    "3. Whenever you change a model:\n",
    "\n",
    "    `alembic revision --autogenerate -m \"describe change\"`\n",
    "   \n",
    "    `alembic upgrade head`\n",
    "\n",
    "This will safely apply only the changes needed, without dropping your tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc7161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base class\n",
    "Base = declarative_base() \n",
    "\n",
    "#---\n",
    "# It creates a registry (Base.metadata) that will hold all the tables you define.\n",
    "# Every time you define a model (class Project(Base): ...), that model’s table gets registered into Base.metadata.tables.\n",
    "#---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef16ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base.metadata.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bd9ed2",
   "metadata": {},
   "source": [
    "# Step 1. Enums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Enums\n",
    "# --------------------------\n",
    "\n",
    "## 1.1 ProjectStatus\n",
    "class ProjectStatus(enum.Enum):\n",
    "    draft = \"draft\"                  # project created, requirements being defined\n",
    "    ready_for_annotation = \"ready_for_annotation\"  # files uploaded, jobs not started\n",
    "    in_progress = \"in_progress\"      # annotation jobs are running\n",
    "    completed = \"completed\"          # all jobs done\n",
    "    archived = \"archived\"            # project closed, read-only\n",
    "\n",
    "## 1.2 FileStatus (file lifecycle)\n",
    "class FileStatus(enum.Enum):\n",
    "    pending = \"pending\"\n",
    "    ready_for_annotation = \"ready_for_annotation\"\n",
    "    in_progress = \"in_progress\"\n",
    "    completed = \"completed\"\n",
    "    archived = \"archived\"\n",
    "\n",
    "## 1.3 FileType\n",
    "class FileType(enum.Enum):\n",
    "    dataset = \"dataset\"\n",
    "    requirement = \"requirement\"\n",
    "    report = \"annotation_results\"\n",
    "    llm_output = \"llm_output\"\n",
    "# Does our PM also needs to upload sliced file results? (NO currently)\n",
    "\n",
    "# ## 1.4 UserRole\n",
    "# class UserRole(enum.Enum):\n",
    "#     org_admin = \"org_admin\"       # customer admin\n",
    "#     org_pm = \"org_pm\"             # customer project manager\n",
    "#     our_pm = \"our_pm\"             # our company PM that manages annotation jobs & assigns annotators\n",
    "#     annotator = \"annotator\"       # our company annotator\n",
    "#     qc = \"qc\"                     # our company QC for annotation results review\n",
    "\n",
    "## 1.5 AnnotationJobStatus (job lifecycle)\n",
    "class AnnotationJobStatus(enum.Enum):\n",
    "    not_started = \"not_started\"\n",
    "    in_progress = \"in_progress\"\n",
    "    submitted = \"submitted\"\n",
    "    reviewed = \"reviewed\"\n",
    "\n",
    "## 1.6 ReviewStatus\n",
    "class ReviewStatus(enum.Enum):\n",
    "    pending = \"pending\"\n",
    "    approved = \"approved\"\n",
    "    rejected = \"rejected\"\n",
    "\n",
    "## 1.7 EntityType\n",
    "class EntityType(enum.Enum):\n",
    "    project = \"project\"\n",
    "    file = \"file\"\n",
    "    file_version = \"file_version\"\n",
    "    annotation_job = \"annotation_job\"\n",
    "\n",
    "## 1.8 EventType\n",
    "class EventType(enum.Enum):\n",
    "    uploaded = \"uploaded\"\n",
    "    reuploaded = \"reuploaded\"\n",
    "    annotation_started = \"annotation_started\"\n",
    "    annotation_completed = \"annotation_completed\"\n",
    "    reviewed = \"reviewed\"\n",
    "    deleted = \"deleted\"\n",
    "    status_changed = \"status_changed\"\n",
    "\n",
    "## 1.9 AssignmentRole\n",
    "class AssignmentRole(enum.Enum):\n",
    "    annotator = \"annotator\"\n",
    "    reviewer = \"reviewer\"\n",
    "    qc = \"qc\"   # quality control / audit\n",
    "\n",
    "## 1.10 Language (for AnnotationJob)\n",
    "class Language(enum.Enum):\n",
    "    en = \"en\"   # English\n",
    "    zh = \"zh\"   # Chinese\n",
    "    fr = \"fr\"   # French\n",
    "    de = \"de\"   # German\n",
    "    es = \"es\"   # Spanish\n",
    "    ar = \"ar\"   # Arabic\n",
    "\n",
    "## 1.11 Priority (for AnnotationJob)\n",
    "class JobPriority(enum.Enum):\n",
    "    low = \"low\"\n",
    "    medium = \"medium\"\n",
    "    high = \"high\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f55815",
   "metadata": {},
   "source": [
    "# Step 2. Association Tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce228213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Association Tables\n",
    "# --------------------------\n",
    "\n",
    "# 2.1 User <-> Role\n",
    "user_roles = Table(\n",
    "    \"user_roles\",\n",
    "    Base.metadata,\n",
    "    Column(\"user_id\", Integer, ForeignKey(\"user.user_id\", ondelete=\"CASCADE\"), primary_key=True),\n",
    "    Column(\"role_id\", Integer, ForeignKey(\"role.role_id\", ondelete=\"CASCADE\"), primary_key=True),\n",
    "    extend_existing=True  \n",
    ")\n",
    "\n",
    "# 2.2 Role <-> Permission\n",
    "role_permissions = Table(\n",
    "    \"role_permissions\",\n",
    "    Base.metadata,\n",
    "    Column(\"role_id\", Integer, ForeignKey(\"role.role_id\", ondelete=\"CASCADE\"), primary_key=True),\n",
    "    Column(\"permission_id\", Integer, ForeignKey(\"permission.permission_id\", ondelete=\"CASCADE\"), primary_key=True),\n",
    "    extend_existing=True  \n",
    ")\n",
    "\n",
    "# This table records which annotators have worked on this job before \n",
    "# (for feedback loops / reassignment tracking)\n",
    "job_previous_annotators = Table(\n",
    "    \"job_previous_annotators\",\n",
    "    Base.metadata,\n",
    "    Column(\"job_id\", Integer, ForeignKey(\"annotation_job.job_id\", ondelete=\"CASCADE\"), primary_key=True),\n",
    "    Column(\"user_id\", Integer, ForeignKey(\"user.user_id\", ondelete=\"CASCADE\"), primary_key=True),\n",
    "    Column(\"assigned_at\", DateTime, default=func.now()),\n",
    "    extend_existing=True  \n",
    ")\n",
    "\n",
    "\n",
    "# One ExportLog may include multiple versions.\n",
    "# One FileVersion may appear in multiple exports\n",
    "class ExportedFile(Base):\n",
    "    __tablename__ = \"exported_file\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    export_id = Column(Integer, ForeignKey(\"export_log.export_id\", ondelete=\"CASCADE\"), primary_key=True)\n",
    "    file_version_id = Column(Integer, ForeignKey(\"file_version.version_id\", ondelete=\"CASCADE\"), primary_key=True)\n",
    "    included_at = Column(DateTime, default=func.now())\n",
    "\n",
    "    # Relationships\n",
    "    export = relationship(\"ExportLog\", back_populates=\"exported_files\")\n",
    "    file_version = relationship(\"FileVersion\", back_populates=\"exported_files\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e975f5e7",
   "metadata": {},
   "source": [
    "# Step 3: CORE TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99218b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_UPDATE_COLS = {\n",
    "    # Project life-cycle\n",
    "    \"project\": {\n",
    "        \"status\",         # workflow stage\n",
    "        \"name\",           # user-visible name\n",
    "        \"description\",    # requirement details\n",
    "        \"client_pm_id\",   # who owns it on client side\n",
    "        \"our_pm_id\",      # our internal PM\n",
    "        \"is_active\"       # soft enable/disable\n",
    "    },\n",
    "\n",
    "    # Files inside a project\n",
    "    \"file\": {\n",
    "        \"status\",         # processing state\n",
    "        \"name\",\n",
    "        \"description\",\n",
    "        \"active_version_id\",  # which version is served\n",
    "        \"is_active\"\n",
    "    },\n",
    "\n",
    "    # Individual file versions (mostly immutable)\n",
    "    \"file_version\": {\n",
    "        \"is_active\",          # whether this version is live\n",
    "        \"generation_method\",  # upload / OCR / LLM\n",
    "        \"llm_model\",          # model used\n",
    "        \"llm_params\"          # model parameters\n",
    "    },\n",
    "\n",
    "    # FileTable for the file uploaded by the client company\n",
    "    \"file_table\": {\n",
    "    \"status\",\n",
    "    \"description\",\n",
    "    \"schema_json\",\n",
    "    \"extracted_narrative\",\n",
    "    \"is_active\"\n",
    "},\n",
    "\n",
    "    # Human users\n",
    "    \"user\": {\n",
    "        \"email\",              # login identifier\n",
    "        \"org_id\",             # organization assignment\n",
    "        \"availability\",       # capacity\n",
    "        \"language_expertise\", # skill profile\n",
    "        \"skill_score\",        # QA/score metrics\n",
    "        \"skill_level\",\n",
    "        \"qa_approval_rate\",   # performance metrics\n",
    "        \"is_active\"\n",
    "    },\n",
    "\n",
    "    # Annotation jobs\n",
    "    \"annotation_job\": {\n",
    "        \"status\",        # job workflow\n",
    "        \"review_status\", # review result\n",
    "        \"priority\",\n",
    "        \"language\",\n",
    "        \"due_date\",\n",
    "        \"is_active\"\n",
    "    },\n",
    "\n",
    "    # Assignment of a job to a user\n",
    "    \"assignment\": {\n",
    "        \"status\",  # assigned → in_progress → completed\n",
    "        \"role\",\n",
    "        \"user_id\"\n",
    "    },\n",
    "\n",
    "    # Reviews on completed jobs\n",
    "    \"review\": {\n",
    "        \"status\",   # pending / approved / rejected\n",
    "        \"feedback\", # reviewer comments\n",
    "        \"is_active\"\n",
    "    },\n",
    "\n",
    "    # Export operations\n",
    "    \"export_log\": {\n",
    "        \"status\",       # pending / completed / failed\n",
    "        \"storage_path\", # destination location\n",
    "        \"checksum\"\n",
    "    },\n",
    "\n",
    "    # Organization meta\n",
    "    \"organization\": {\n",
    "        \"name\",\n",
    "        \"description\",\n",
    "        \"is_active\"\n",
    "    },\n",
    "\n",
    "    # Event log rows are append-only — no updates expected.\n",
    "    # If you ever allow edits, list those columns here.\n",
    "    # \"event_log\": set(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bf2470",
   "metadata": {},
   "source": [
    "## 3.1 Project Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ccc80484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/3851405211.py:6: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.Project, and will be replaced in the string-lookup table.\n",
      "  class Project(Base, TimestampMixin):\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Core Tables\n",
    "# -----------------------------\n",
    "    \n",
    "# Project Table\n",
    "class Project(Base, TimestampMixin):\n",
    "    __tablename__ = \"project\"\n",
    "    __table_args__ = (\n",
    "    UniqueConstraint(\"org_id\", \"name\", name=\"uq_org_project_name\"), # no two projects can share same name in one comp\n",
    "    Index(\"ix_project_status\", \"status\"), # speeds up dashboards like “show me all in-progress projects”.\n",
    "    Index(\"ix_project_is_active\", \"is_active\"), # speeds up “only show active projects”.\n",
    "    Index(\"ix_project_client_pm_id\", \"client_pm_id\"), # useful if query “all projects started by this PM”.\n",
    "    Index(\"ix_project_org_id\", \"org_id\"), # useful if query “all projects for this org”.\n",
    "    {\"extend_existing\": True} # delete\n",
    "    )\n",
    "\n",
    "    project_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    org_id = Column(Integer, ForeignKey(\"organization.org_id\"), nullable=False)\n",
    "    name = Column(String, nullable=False)\n",
    "    description = Column(Text, nullable=True) # longer desp than name\n",
    "\n",
    "    # plain text instructions\n",
    "    requirements_text = Column(Text, nullable=True)\n",
    "    # optional uploaded doc (PDF, Word, PPT, etc.)\n",
    "    # requirements_file_id = Column(Integer, ForeignKey(\"file.file_id\"), nullable=True)\n",
    "\n",
    "    # project status enum\n",
    "    status = Column(Enum(ProjectStatus, name=\"project_status_enum\"), default=ProjectStatus.draft)\n",
    "    \n",
    "    is_active = Column(Boolean, default=True, nullable=False)\n",
    "\n",
    "    date_created = Column(DateTime, default=func.now(), nullable=False)\n",
    "    date_updated = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n",
    "    completed_at = Column(DateTime, nullable=True)\n",
    "    deleted_at = Column(DateTime, nullable=True) # when customer delete the project\n",
    "\n",
    "    # --- PM links ---\n",
    "    client_pm_id = Column(Integer, ForeignKey(\"user.user_id\"), nullable=False) # client PM\n",
    "    our_pm_id = Column(Integer, ForeignKey(\"user.user_id\"), nullable=True) # our PM\n",
    "\n",
    "    # --- Relationships ---\n",
    "    files = relationship(\"File\", back_populates=\"project\")             # all files\n",
    "    # convenience: only requirement files\n",
    "    requirement_files = relationship(\n",
    "        \"File\",\n",
    "        primaryjoin=\"and_(Project.project_id==File.project_id, File.file_type=='requirement')\",\n",
    "        viewonly=True\n",
    "    ) # only get files that accords with reqs\n",
    "    jobs = relationship(\"AnnotationJob\", back_populates=\"project\")     # all jobs\n",
    "    events = relationship(\"EventLog\", back_populates=\"project\")        # all events\n",
    "    organization = relationship(\"Organization\", back_populates=\"projects\")\n",
    "    client_pm = relationship(\"User\", foreign_keys=[client_pm_id], back_populates=\"client_projects\")\n",
    "    our_pm = relationship(\"User\", foreign_keys=[our_pm_id], back_populates=\"managed_projects\")\n",
    "    exports = relationship(\"ExportLog\", back_populates=\"project\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb06e27",
   "metadata": {},
   "source": [
    "## 3.2 File Table \n",
    "(currently only create one for all kinds of files' storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5264bf1f",
   "metadata": {},
   "source": [
    "check the logic:\n",
    "1. files that clients uploaded, our PM needs to be able to view it so that they can further assign tasks;     \n",
    "2. files that clients uploaded, needs to be able to transport to LLM model(maybe it's sth in backend?)     \n",
    "3. annotator also needs relevant access, because for each task they needs the correspond raw file for annotation   \n",
    "4. quality checker also need them to check the work done by the annotator.     \n",
    "5. clients needs to be able to view the files they had uploaded and see the progress     \n",
    "6. organizations also needs to be able to view all the projects as well as all the files their company uploaded and created.    \n",
    "7. for the llm generated file, the annotator need to have access to it for corresponding task;     \n",
    "8. for annotated file uploaded by annotators, they needs to be able to send to quality checker;     \n",
    "9. the files that's approved by quality check needs to be able to back to customers     \n",
    "10. the organization needs to have access to all the final annotated files     \n",
    "11. the client PM needs to have access to the final annotated files that they uploaded     \n",
    "12. during uploading, each project allow customer to upload multiple files with different versions, only by clicking sth like \"confirmation\" will one project be created, and when project created, all files will be in pending status \n",
    "13. raw files can be deleted by customers before the task is processing (can be deleted during pending status)     \n",
    "14. one project only related to one client, but one client can relate to many projects     \n",
    "15. one file only related to one projects, but only projects can have multiple files,     \n",
    "16. when deleting a project, all the files under this project will be inactive,    \n",
    "17. both project manager in client company and the corresponding organization can have the access to delete the project(but client can only delete the project they created)    \n",
    "18. further link with file size and format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b859e98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/87485939.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.File, and will be replaced in the string-lookup table.\n",
      "  class File(Base, TimestampMixin):\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# File Table\n",
    "# --------------------------\n",
    "class File(Base, TimestampMixin):\n",
    "    __tablename__ = \"file\"\n",
    "    __table_args__ = (\n",
    "    UniqueConstraint(\"project_id\", \"name\", name=\"uq_project_file_name\"),\n",
    "    Index(\"ix_file_project_id\", \"project_id\"), # speeds up “all files in project.”\n",
    "    Index(\"ix_file_status\", \"status\"), # speeds up “all files ready for annotation.”\n",
    "    Index(\"ix_file_type\", \"file_type\"), # speeds up filtering datasets vs. requirements.\n",
    "    {\"extend_existing\": True},\n",
    ")\n",
    "\n",
    "\n",
    "    file_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    # descriptive file name (user-facing)\n",
    "    name = Column(String, nullable=False)\n",
    "    description = Column(Text, nullable=True)\n",
    "    uploaded_by = Column(Integer, ForeignKey(\"user.user_id\"), nullable=False)\n",
    "\n",
    "\n",
    "    # workflow state\n",
    "    status = Column(\n",
    "        Enum(FileStatus, name=\"file_status_enum\"),\n",
    "        default=FileStatus.pending,\n",
    "        nullable=False\n",
    "    )\n",
    "    # what kind of file this is (dataset, requirement, annotation_results, llm_nl)\n",
    "    file_type = Column(Enum(FileType, name=\"file_type_enum\"), nullable=False, default=FileType.dataset)\n",
    "\n",
    "    # audit timestamps\n",
    "    date_created = Column(DateTime, default=func.now(), nullable=False)\n",
    "    date_updated = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n",
    "    is_active = Column(Boolean, default=True, nullable=False)\n",
    "    deleted_at = Column(DateTime, nullable=True)\n",
    "\n",
    "    # validate uploads by storage\n",
    "    size_bytes = Column(Integer, nullable=True)\n",
    "    mime_type = Column(String, nullable=True) # technical format\n",
    "\n",
    "    \n",
    "    # --- PM links ---\n",
    "    project_id = Column(Integer, ForeignKey(\"project.project_id\"), nullable=False)\n",
    "    # active version pointer\n",
    "    active_version_id = Column(Integer, ForeignKey(\"file_version.version_id\"), nullable=True)\n",
    "\n",
    "\n",
    "    # --- Relationships ---\n",
    "    uploader = relationship(\"User\", back_populates=\"uploaded_files\")\n",
    "    project = relationship(\"Project\", back_populates=\"files\")\n",
    "    versions = relationship(\"FileVersion\", back_populates=\"file\", cascade=\"all, delete-orphan\")\n",
    "    events = relationship(\"EventLog\", back_populates=\"file\")\n",
    "    active_version = relationship(\"FileVersion\", foreign_keys=[active_version_id], uselist=False)\n",
    "    tables = relationship(\"FileTable\", back_populates=\"file\", cascade=\"all, delete-orphan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d8ee00",
   "metadata": {},
   "source": [
    "## 3.3 File Version Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3a5063f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/1825405250.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.FileVersion, and will be replaced in the string-lookup table.\n",
      "  class FileVersion(Base, TimestampMixin):\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Version Table\n",
    "# --------------------------\n",
    "class FileVersion(Base, TimestampMixin):\n",
    "    __tablename__ = \"file_version\"\n",
    "    __table_args__ = (\n",
    "        Index(\"ix_fileversion_file_id\", \"file_id\"),\n",
    "        {\"extend_existing\": True},\n",
    "    )\n",
    "\n",
    "    version_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "\n",
    "    # --- Parent link ---\n",
    "    file_id = Column(Integer, ForeignKey(\"file.file_id\", ondelete=\"CASCADE\"), nullable=False)\n",
    "    version_number = Column(Integer, nullable=False)  # 1, 2, 3…\n",
    "\n",
    "    # --- Storage info ---\n",
    "    storage_path = Column(String, nullable=False)   # MinIO/S3 key or path\n",
    "    checksum = Column(String, nullable=True)        # for integrity validation\n",
    "    size_bytes = Column(Integer, nullable=True)     # optional: store size at version-level\n",
    "    mime_type = Column(String, nullable=True)       # optional: file format at version-level\n",
    "\n",
    "    # --- Upload & provenance ---\n",
    "    uploaded_by = Column(Integer, ForeignKey(\"user.user_id\"), nullable=True)\n",
    "    uploaded_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)\n",
    "    # --- Lifecycle flags ---\n",
    "    is_active = Column(Boolean, default=True, nullable=False)\n",
    "\n",
    "    source_file_version_id = Column(Integer, ForeignKey(\"file_version.version_id\"), nullable=True)\n",
    "    generation_method = Column(\n",
    "        Enum(\"upload\", \"ocr\", \"llm\", name=\"generation_method_enum\"),\n",
    "        default=\"upload\",\n",
    "        nullable=False\n",
    "    )\n",
    "    llm_model = Column(String, nullable=True)       # e.g., \"gpt-4\", \"llama-3\"\n",
    "    llm_params = Column(JSON, nullable=True)        # parameters if generated by LLM\n",
    "\n",
    "\n",
    "    # --- Relationships ---\n",
    "    file = relationship(\"File\", back_populates=\"versions\")\n",
    "    source_version = relationship(\"FileVersion\", remote_side=[version_id])  # self-ref\n",
    "    events = relationship(\"EventLog\", back_populates=\"file_version\")        # version-level logs\n",
    "    exports = relationship(\n",
    "    \"ExportLog\",\n",
    "    secondary=\"exported_file\",\n",
    "    back_populates=\"file_versions\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # export_id = Column(Integer, ForeignKey(\"export_log.export_id\"), nullable=True)\n",
    "    exported_files = relationship(\n",
    "        \"ExportedFile\",\n",
    "        back_populates=\"file_version\",\n",
    "        cascade=\"all, delete-orphan\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29cd974",
   "metadata": {},
   "source": [
    "## 3.4 FileTable Table\n",
    "\n",
    "the logic of this table should start with, the project manager in other company, they create a project, and in the project, there may upload multiple files for annotation, that's ok, but then these files will be put in LLM and LLM will partition them into tables, and generate natural language for that file; and our product manager will assign each table and the corresponding natural language generated by llm to different annotators, and each annotator will do further annotation, also later when each task is finished, they will be given to quality checker for checking and they may choose to complete this project or send back with feedback to annotators to modify their annotations, for each table is linked with a file, and each file can have multiple tables, when a file is pending, product managers from other company can re-upload this file, if all the files are pending, they can even delete the project; but if they are in process, they are no longer allowed to delete, and finally if all the tables are completed by quality checker, then in product manager's interfaceI(both our company and client company) it shows that the file is finished; if all the files are completed, then in product manager's interface(both our company pm and the client company pm) it shows that the project is completed and PM in client's company are allowed to download everything as a zip. so at first, the progress is tracked by file, then the task is linked to each table and all the tables status lead to the status of the file and all the files' status lead to the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf75cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileTable(Base, TimestampMixin):\n",
    "    __tablename__ = \"file_table\"\n",
    "    __table_args__ = (\n",
    "        Index(\"ix_table_file_id\", \"file_id\"),\n",
    "        Index(\"ix_table_status\", \"status\"),\n",
    "        {\"extend_existing\": True},\n",
    "    )\n",
    "\n",
    "    table_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "\n",
    "    # Each table belongs to exactly one file\n",
    "    file_id = Column(Integer, ForeignKey(\"file.file_id\", ondelete=\"CASCADE\"), nullable=False)\n",
    "    version_id = Column(Integer, ForeignKey(\"file_version.version_id\", ondelete=\"SET NULL\"), nullable=True)\n",
    "\n",
    "    # Metadata for traceability\n",
    "    name = Column(String, nullable=True)      # optional, e.g., \"Table 3: Revenue Summary\"\n",
    "    description = Column(Text, nullable=True) # optional text or auto-detected caption\n",
    "\n",
    "    # JSON column to store table schema or preview content\n",
    "    schema_json = Column(JSONB, nullable=True)  # {\"columns\": [\"col1\", \"col2\"], \"types\": [\"str\", \"float\"]}\n",
    "    extracted_narrative = Column(Text, nullable=True)  # the LLM-generated NL paragraph for that table\n",
    "\n",
    "    # Table-level workflow\n",
    "    status = Column(\n",
    "        Enum(FileStatus, name=\"filetable_status_enum\"),\n",
    "        default=FileStatus.pending,\n",
    "        nullable=False\n",
    "    )\n",
    "\n",
    "    # Audit\n",
    "    is_active = Column(Boolean, default=True, nullable=False)\n",
    "    deleted_at = Column(DateTime, nullable=True)\n",
    "\n",
    "    # --- Relationships ---\n",
    "    file = relationship(\"File\", back_populates=\"tables\")\n",
    "    version = relationship(\"FileVersion\", back_populates=\"tables\", foreign_keys=[version_id])\n",
    "    jobs = relationship(\"AnnotationJob\", back_populates=\"table\", cascade=\"all, delete-orphan\")\n",
    "    events = relationship(\"EventLog\", back_populates=\"table\", cascade=\"all, delete-orphan\")\n",
    "    #tables = relationship(\"FileTable\", back_populates=\"version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b6bd97",
   "metadata": {},
   "source": [
    "## 3.4 User Table\n",
    "\n",
    "\"user\" is a generic account table that represents any actor in the system:\n",
    "\n",
    "* Organization Admin (client company, oversees all projects).\n",
    "\n",
    "* Organization PM (client company, uploads datasets + requirements).\n",
    "\n",
    "* Our PM (your company, manages annotation jobs & assigns annotators).\n",
    "\n",
    "* Annotators (our company, upload results).\n",
    "\n",
    "* QC / Reviewers (our company, upload corrections).\n",
    "\n",
    "therefore, \"user\" here basically means everyone who logs in and interacts with the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db51942",
   "metadata": {},
   "source": [
    "product manager(our company):\n",
    "\n",
    "1. able to check the availability of the annotators and quality checkers\n",
    "2. able to check for each file, who and how many annotators have annotated that\n",
    "3. able to check the files uploaded by the client company’s PM or uploaded by the organization\n",
    "4. have access to projects and further assign annotators to each project to conduct annotation job \n",
    "5. have access to reassign annotators for same project\n",
    "6. have access to assign quality checker (one people can both be quality checker and annotator the same time, but for each project, if one person can either be quality checker or annotator)\n",
    "\n",
    "client company’s PM:\n",
    "\n",
    "1. able to upload files and create project\n",
    "2. able to view the files/projects they uploaded/created before\n",
    "3. not able to see the files/projects uploaded by others\n",
    "4. able to view the status of the projects/files\n",
    "5. able to resend files if the original project is pending(not in process)\n",
    "\n",
    "organization:\n",
    "\n",
    "1. able to upload files and create project\n",
    "2. able to view all the files/projects their company’s PM uploaded/created before\n",
    "\n",
    "LLM:\n",
    "\n",
    "1. get the files uploaded by client company’s PM\n",
    "2. generate natural language file according to the files\n",
    "\n",
    "our annotators:\n",
    "\n",
    "1. able to view the raw files and projects assigned to them that are uploaded by organization/ client company’s PM\n",
    "2. able to upload their finished annotated files\n",
    "3. able to get the natural language files generated by LLM\n",
    "\n",
    "our quality checker:\n",
    "\n",
    "1. able to view the raw files \n",
    "2. able to view the finished annotated files \n",
    "3. able to approve/ need modification of the annotated files and able to send back to annotators\n",
    "4. able to write down feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d82f6c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/627162196.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.User, and will be replaced in the string-lookup table.\n",
      "  class User(Base, TimestampMixin):\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# User Table\n",
    "# --------------------------\n",
    "class User(Base, TimestampMixin):\n",
    "    __tablename__ = \"user\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    # --- Core fields ---\n",
    "    user_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    email = Column(String, unique=True, nullable=False, index=True)\n",
    "    #role = Column(Enum(UserRole, name=\"user_role_enum\"), nullable=False)\n",
    "\n",
    "    org_id = Column(\n",
    "        Integer,\n",
    "        ForeignKey(\"organization.org_id\", ondelete=\"SET NULL\"),\n",
    "        nullable=True\n",
    "    ) # better: keep user even if org deleted\n",
    "\n",
    "    # --- Availability & Skills ---\n",
    "    availability = Column(JSON, nullable=True)             # weekly availability\n",
    "    language_expertise = Column(JSON, nullable=True)       # {\"en\": 4.5, \"zh\": 3.0}\n",
    "    skill_score = Column(Float, nullable=True)             # overall skill score\n",
    "    skill_level = Column(String, nullable=True)           \n",
    "    qa_approval_rate = Column(Float, nullable=True)        # average QA pass rate\n",
    "    completed_task_count = Column(Integer, default=0)      # total tasks completed\n",
    "\n",
    "    # --- Relationships ---\n",
    "    uploaded_files = relationship(\"File\", back_populates=\"uploader\")\n",
    "    events = relationship(\"EventLog\", back_populates=\"user\")\n",
    "    assignments = relationship(\"Assignment\", back_populates=\"user\", cascade=\"all, delete-orphan\")\n",
    "\n",
    "    is_active = Column(Boolean, default=True, nullable=False)\n",
    "    #roles = relationship(\"Role\", secondary=user_roles, back_populates=\"users\")\n",
    "\n",
    "    # PM links\n",
    "    client_projects = relationship(\"Project\", back_populates=\"client_pm\")\n",
    "    # make sure our PM has access to projects and further assign annotators\n",
    "    managed_projects = relationship(\"Project\", back_populates=\"our_pm\")\n",
    "\n",
    "    # Historical job links\n",
    "    # Records which annotators have worked on this job before\n",
    "    # (for feedback loops / reassignment tracking)\n",
    "    previous_jobs = relationship(\n",
    "        \"AnnotationJob\",\n",
    "        secondary=\"job_previous_annotators\",\n",
    "        back_populates=\"previous_annotators\"\n",
    "    )\n",
    "\n",
    "    reviews = relationship(\"Review\", back_populates=\"reviewer\")\n",
    "    roles = relationship(\"Role\", secondary=user_roles, back_populates=\"users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b3368",
   "metadata": {},
   "source": [
    "    # --- Availability ---\n",
    "    # Store weekly availability / working hours in JSON\n",
    "    # Example:\n",
    "    # {\n",
    "    #   \"monday\": [\"09:00-12:00\", \"13:00-17:00\"],\n",
    "    #   \"tuesday\": [\"10:00-18:00\"],\n",
    "    #   \"wednesday\": []\n",
    "    # }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df817c6c",
   "metadata": {},
   "source": [
    "## 3.5 Annotation Job Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8e44d4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/2184252037.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.AnnotationJob, and will be replaced in the string-lookup table.\n",
      "  class AnnotationJob(Base, TimestampMixin):\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Annotation Job Table\n",
    "# --------------------------\n",
    "class AnnotationJob(Base, TimestampMixin):\n",
    "    __tablename__ = \"annotation_job\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    job_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "\n",
    "    # --- Foreign keys ---\n",
    "    project_id = Column(Integer, ForeignKey(\"project.project_id\", ondelete=\"CASCADE\"), nullable=False)\n",
    "    table_id = Column(Integer, ForeignKey(\"file_table.table_id\", ondelete=\"CASCADE\"), nullable=False)\n",
    "    #file_id = Column(Integer, ForeignKey(\"file.file_id\", ondelete=\"CASCADE\"), nullable=True)  # optional convenience link\n",
    "\n",
    "    # --- Job attributes ---\n",
    "    language = Column(Enum(Language, name=\"annotation_job_language_enum\"), nullable=True)\n",
    "    priority = Column(Enum(JobPriority, name=\"job_priority_enum\"), default=JobPriority.medium, nullable=False)\n",
    "    status = Column(Enum(AnnotationJobStatus, name=\"annotation_job_status_enum\"),\n",
    "                    default=AnnotationJobStatus.not_started, nullable=False)\n",
    "    review_status = Column(Enum(ReviewStatus, name=\"review_status_enum\"),\n",
    "                           default=ReviewStatus.pending, nullable=False)\n",
    "\n",
    "    due_date = Column(DateTime, nullable=True)\n",
    "    completed_at = Column(DateTime, nullable=True)\n",
    "    is_active = Column(Boolean, default=True, nullable=False)\n",
    "    deleted_at = Column(DateTime, nullable=True)\n",
    "\n",
    "    # --- Relationships ---\n",
    "    table = relationship(\"FileTable\", back_populates=\"jobs\")  # main link\n",
    "    project = relationship(\"Project\", back_populates=\"jobs\")\n",
    "\n",
    "    reviews = relationship(\"Review\", back_populates=\"job\", cascade=\"all, delete-orphan\")\n",
    "    assignments = relationship(\"Assignment\", back_populates=\"job\", cascade=\"all, delete-orphan\")\n",
    "\n",
    "    previous_annotators = relationship(\n",
    "        \"User\",\n",
    "        secondary=\"job_previous_annotators\",\n",
    "        back_populates=\"previous_jobs\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57f933",
   "metadata": {},
   "source": [
    "## 3.6 Event Log Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3538b350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/4163952190.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.EventLog, and will be replaced in the string-lookup table.\n",
      "  class EventLog(Base, TimestampMixin):\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Event Log Table\n",
    "# --------------------------\n",
    "class EventLog(Base, TimestampMixin):\n",
    "    __tablename__ = \"event_log\"\n",
    "    __table_args__ = (\n",
    "        Index(\"ix_eventlog_entity\", \"entity_type\", \"entity_id\"),  # speeds up \"get events for this entity\"\n",
    "        {\"extend_existing\": True},\n",
    "    )\n",
    "\n",
    "    event_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "   \n",
    "\n",
    "    # Generic entity pointer\n",
    "    entity_type = Column(Enum(EntityType, name=\"entity_type_enum\"), nullable=False)\n",
    "    entity_id = Column(Integer, nullable=False)  # e.g. file_id, project_id, etc.\n",
    "\n",
    "    # Event classification\n",
    "    event_type = Column(Enum(EventType, name=\"event_type_enum\"), nullable=False)\n",
    "\n",
    "    # Who triggered the event\n",
    "    user_id = Column(Integer, ForeignKey(\"user.user_id\", ondelete=\"SET NULL\"), nullable=True)\n",
    "    user = relationship(\"User\", back_populates=\"events\")\n",
    "\n",
    "    # Flexible metadata\n",
    "    event_metadata = Column(JSONB, nullable=True)  # {\"old_status\": \"pending\", \"new_status\": \"in_progress\"}\n",
    "\n",
    "    # Audit\n",
    "    event_time = Column(DateTime, default=func.now(), nullable=False)\n",
    "\n",
    "    # Optional direct links for efficient joins\n",
    "    file_id = Column(Integer, ForeignKey(\"file.file_id\", ondelete=\"SET NULL\"), nullable=True)\n",
    "    file_version_id = Column(Integer, ForeignKey(\"file_version.version_id\", ondelete=\"SET NULL\"), nullable=True)\n",
    "    project_id = Column(Integer, ForeignKey(\"project.project_id\", ondelete=\"SET NULL\"), nullable=True)\n",
    "    job_id = Column(Integer, ForeignKey(\"annotation_job.job_id\", ondelete=\"SET NULL\"), nullable=True)\n",
    "    export_id = Column(Integer, ForeignKey(\"export_log.export_id\", ondelete=\"SET NULL\"), nullable=True)\n",
    "    review_id = Column(\n",
    "    Integer,\n",
    "    ForeignKey(\"review.review_id\", ondelete=\"CASCADE\"),\n",
    "    nullable=True\n",
    "    )\n",
    "    table_id = Column(Integer, ForeignKey(\"file_table.table_id\", ondelete=\"SET NULL\"), nullable=True)\n",
    "\n",
    "    # Relationships\n",
    "    project = relationship(\"Project\", back_populates=\"events\")\n",
    "    file = relationship(\"File\", back_populates=\"events\")\n",
    "    file_version = relationship(\"FileVersion\", back_populates=\"events\")\n",
    "    job = relationship(\"AnnotationJob\", back_populates=\"events\")\n",
    "    export = relationship(\"ExportLog\", back_populates=\"events\")\n",
    "    review = relationship(\"Review\", back_populates=\"events\")\n",
    "    table = relationship(\"FileTable\", back_populates=\"events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9841251f",
   "metadata": {},
   "source": [
    "## 3.7 Review Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59053916",
   "metadata": {},
   "source": [
    "1. quality checkers will review each annotated file done by each annotators     \n",
    "2. one llm_generated file may assign to more than one annotators, so quality checker may see same file but annotated by different annotators and need to give feedback each     \n",
    "3. each annotators would be able to see the reviews and clearly know the correspond file so that they can make further edition     \n",
    "4. there exist condition about previous annotators, so that our PM can see who and how many people have edited one particular file     \n",
    "5. each annotator can view the feedback history they gotten and know which quality checker gave which to them, each quality checker can check the feedback history they written and also to which annotator while one person can both be quality checker and annotator(but under different projects, not under same project)     \n",
    "6. all reviews does not include file (just plain text wrote in the box in website) but these also needs to be stored and can not be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4a29ed25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/1003076118.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.Review, and will be replaced in the string-lookup table.\n",
      "  class Review(Base, TimestampMixin):\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Review Table\n",
    "# --------------------------\n",
    "class Review(Base, TimestampMixin):\n",
    "    __tablename__ = \"review\"\n",
    "    __table_args__ = (\n",
    "    Index(\"ix_review_job_id\", \"job_id\"),\n",
    "    Index(\"ix_review_status\", \"status\"),\n",
    "    {\"extend_existing\": True},\n",
    ")\n",
    "\n",
    "\n",
    "    review_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "\n",
    "    # Link to the job being reviewed\n",
    "    job_id = Column(Integer, ForeignKey(\"annotation_job.job_id\", ondelete=\"CASCADE\"), nullable=False)\n",
    "\n",
    "    # Reviewer (user with reviewer role)\n",
    "    reviewer_id = Column(Integer, ForeignKey(\"user.user_id\", ondelete=\"SET NULL\"), nullable=True)\n",
    "\n",
    "    # Review decision\n",
    "    status = Column(\n",
    "        Enum(ReviewStatus, name=\"review_table_status_enum\"),\n",
    "        default=ReviewStatus.pending,\n",
    "        nullable=False\n",
    "    )\n",
    "\n",
    "    # Optional comments from reviewer\n",
    "    feedback = Column(Text, nullable=True)\n",
    "\n",
    "\n",
    "    # Audit timestamps\n",
    "    # created_at = Column(DateTime, default=func.now(), nullable=False)\n",
    "    # updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n",
    "\n",
    "    # Soft delete fields (prevents permanent data loss)\n",
    "    is_active = Column(Boolean, default=True, nullable=False)\n",
    "    deleted_at = Column(DateTime, nullable=True)\n",
    "\n",
    "\n",
    "    # Relationships\n",
    "    job = relationship(\"AnnotationJob\", back_populates=\"reviews\")\n",
    "    reviewer = relationship(\"User\", back_populates=\"reviews\")\n",
    "    events = relationship(\"EventLog\", back_populates=\"review\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8330cbc",
   "metadata": {},
   "source": [
    "## 3.8 Assignment Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d7b9d3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/3084525935.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.Assignment, and will be replaced in the string-lookup table.\n",
      "  class Assignment(Base, TimestampMixin):\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Assignment Table\n",
    "# --------------------------\n",
    "class Assignment(Base, TimestampMixin):\n",
    "    __tablename__ = \"assignment\"\n",
    "    __table_args__ = (\n",
    "        Index(\"ix_assignment_job_id\", \"job_id\"),\n",
    "        Index(\"ix_assignment_user_id\", \"user_id\"),\n",
    "        Index(\"ix_assignment_role\", \"role\"),\n",
    "        {\"extend_existing\": True},\n",
    "    )\n",
    "\n",
    "    assignment_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "\n",
    "    # Link to the annotation job (one job = one file version to be annotated)\n",
    "    job_id = Column(\n",
    "        Integer,\n",
    "        ForeignKey(\"annotation_job.job_id\", ondelete=\"CASCADE\"),\n",
    "        nullable=False\n",
    "    )\n",
    "\n",
    "    # Who is assigned\n",
    "    user_id = Column(\n",
    "        Integer,\n",
    "        ForeignKey(\"user.user_id\", ondelete=\"CASCADE\"),\n",
    "        nullable=False\n",
    "    )\n",
    "\n",
    "    # Role in this job (annotator, reviewer, qc)\n",
    "    role = Column(Enum(AssignmentRole, name=\"assignment_role_enum\"), nullable=False)\n",
    "\n",
    "    # Status of this assignment (separate from job status)\n",
    "    status = Column(\n",
    "        Enum(\"assigned\", \"accepted\", \"in_progress\", \"submitted\", \"completed\",\n",
    "             name=\"assignment_status_enum\"),\n",
    "        default=\"assigned\",\n",
    "        nullable=False\n",
    "    )\n",
    "\n",
    "    # Whether this assignment is currently active (soft delete for history)\n",
    "    is_active = Column(Boolean, default=True, nullable=False)\n",
    "    completed_at = Column(DateTime, nullable=True)\n",
    "\n",
    "    # Audit fields\n",
    "    assigned_at = Column(DateTime, default=func.now(), nullable=False)\n",
    "    updated_at = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n",
    "\n",
    "    # Relationships\n",
    "    job = relationship(\"AnnotationJob\", back_populates=\"assignments\")\n",
    "    user = relationship(\"User\", back_populates=\"assignments\")\n",
    "\n",
    "    # Track reviews connected to this assignment (indirectly through job)\n",
    "    # reviews = relationship(\n",
    "    #     \"Review\",\n",
    "    #     secondary=\"annotation_job\",  # review links via job_id\n",
    "    #     viewonly=True\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ff8b7",
   "metadata": {},
   "source": [
    "## 3.9 Role&Permission Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04d85f",
   "metadata": {},
   "source": [
    "1. For client company PMs, their rights and permission are:\n",
    "\n",
    "can upload multiple files for one project and can can only view the files they themselves uploaded;\n",
    "\n",
    "can create multiple projects and can only view the project they themselves created;\n",
    "\n",
    "can view the annotated files finished and approved by quality checkers;\n",
    "\n",
    "can not view the llm generated files nor view the annotated but not approved files;\n",
    "\n",
    "allow one PM that does not belongs to any organization but not allow one same PM belongs to multiple companies;\n",
    "\n",
    "can edit project and re-upload files as long as the project and the file are in pending(not in progress or completed…)\n",
    "\n",
    "2. For organization, their rights and permission are:\n",
    "\n",
    "can upload multiple files for one project and can can view the files they themselves uploaded;\n",
    "\n",
    "can create multiple projects and can view the project they themselves created;\n",
    "\n",
    "can view the files uploaded by their own company’s PMs, projects created by their own company’s PMs;\n",
    "\n",
    "can view the annotated files finished and approved by quality checkers as long as these files corresponds to the files uploaded by their company’s PMs;\n",
    "\n",
    "3. For our company product manager:\n",
    "\n",
    "can view the projects  created by client company PMs;\n",
    "\n",
    "can assign files to annotators;\n",
    "\n",
    "can check the status of the projects and files;\n",
    "\n",
    "can assign one file to multiple annotators;\n",
    "\n",
    "can assign annotated files to quality checkers;\n",
    "\n",
    "can reassign file to different annotators (avoiding the original annotator) (support Reassignment and Feedback Loop function);\n",
    "\n",
    "no two PMs in our company can assign same project or files (to avoid overlaps);\n",
    "\n",
    "can choose when to finish a project after see all the annotated files from same project completed by quality checkers;\n",
    "\n",
    "4. For annotators:\n",
    "\n",
    "cannot be assigned to same file more than once if it’s not from the feedback for refinement (support reassignment and Feedback Loop function);\n",
    "\n",
    "can have multiple projects’ file annotation job;\n",
    "\n",
    "can have feedback from quality checker and know the pointed file;\n",
    "\n",
    "can get llm-generated file and upload their annotated files\n",
    "\n",
    "5. For quality checker:\n",
    "\n",
    "can make multiple feedback for same file;\n",
    "\n",
    "can choose to complete or give feedback for each file;\n",
    "\n",
    "(cannot have access to llm generated file, not sure about this point, whether needs to have access)\n",
    "\n",
    "can have access to raw files uploaded by clients company PMs or organizations;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ba1fe737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/3776670419.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.Role, and will be replaced in the string-lookup table.\n",
      "  class Role(Base, TimestampMixin):\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Role Table\n",
    "# --------------------------\n",
    "class Role(Base, TimestampMixin):\n",
    "    __tablename__ = \"role\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    role_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    name = Column(String, unique=True, nullable=False)   # e.g. \"annotator\", \"qc\", \"pm\"\n",
    "    description = Column(Text, nullable=True)            # human-readable explanation\n",
    "\n",
    "    # Relationships\n",
    "    users = relationship(\"User\", secondary=user_roles, back_populates=\"roles\")\n",
    "    permissions = relationship(\"Permission\", secondary=role_permissions, back_populates=\"roles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4188603d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/2444035327.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.Permission, and will be replaced in the string-lookup table.\n",
      "  class Permission(Base, TimestampMixin):\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Permission Table\n",
    "# --------------------------\n",
    "class Permission(Base, TimestampMixin):\n",
    "    __tablename__ = \"permission\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    permission_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    name = Column(String, unique=True, nullable=False)   # e.g. \"upload_file\", \"assign_job\", \"review_annotation\"\n",
    "    description = Column(Text, nullable=True)            # what this permission means in plain English\n",
    "\n",
    "    # Relationships\n",
    "    roles = relationship(\"Role\", secondary=role_permissions, back_populates=\"permissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1f4e2",
   "metadata": {},
   "source": [
    "## 3.10 Organization Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3624754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/7thpxjgs3m38yh7ftdr5g7vm0000gn/T/ipykernel_97036/338503639.py:4: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.Organization, and will be replaced in the string-lookup table.\n",
      "  class Organization(Base, TimestampMixin):\n"
     ]
    }
   ],
   "source": [
    "from .project import Project\n",
    "# ------------------------------\n",
    "# Organization Table\n",
    "# ------------------------------\n",
    "class Organization(Base, TimestampMixin):\n",
    "    __tablename__ = \"organization\"\n",
    "    __table_args__ = (\n",
    "        Index(\"ix_org_name\", \"name\"),  # speed up lookups by name\n",
    "        {\"extend_existing\": True},\n",
    "    )\n",
    "\n",
    "    org_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "\n",
    "    # Basic info\n",
    "    name = Column(String, unique=True, nullable=False)   # e.g. \"Acme Corp\"\n",
    "    description = Column(Text, nullable=True)            # optional, for notes\n",
    "\n",
    "    # Lifecycle & audit\n",
    "    is_active = Column(Boolean, default=True, nullable=False)\n",
    "    deleted_at = Column(DateTime, nullable=True)\n",
    "    date_created = Column(DateTime, default=func.now(), nullable=False)\n",
    "    date_updated = Column(DateTime, default=func.now(), onupdate=func.now(), nullable=False)\n",
    "\n",
    "    # --------------------------\n",
    "    # Relationships\n",
    "    # --------------------------\n",
    "    # All users belonging to this org\n",
    "    users = relationship(\n",
    "        \"User\",\n",
    "        back_populates=\"organization\",\n",
    "        passive_deletes=True,\n",
    "    )\n",
    "\n",
    "    # All projects created under this org\n",
    "    projects = relationship(\n",
    "        \"Project\",\n",
    "        back_populates=\"organization\",\n",
    "        passive_deletes=True,\n",
    "    )\n",
    "\n",
    "    # Convenience: get all files uploaded under this org (via projects)\n",
    "    files = relationship(\n",
    "        \"File\",\n",
    "        secondary=\"project\",  # indirect join via Project.project_id\n",
    "        viewonly=True,\n",
    "        primaryjoin=\"Organization.org_id==Project.org_id\",\n",
    "        secondaryjoin=\"Project.project_id==File.project_id\",\n",
    "    )\n",
    "\n",
    "    # Event logs linked to this org (optional, via project/file/user actions)\n",
    "    events = relationship(\n",
    "        \"EventLog\",\n",
    "        secondary=Project.__table__,\n",
    "        primaryjoin=\"Organization.org_id == Project.org_id\",\n",
    "        secondaryjoin=\"Project.project_id == EventLog.project_id\",\n",
    "        viewonly=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1088bf58",
   "metadata": {},
   "source": [
    "## 3.11 Export / Report tables\n",
    "stores generated ZIPs or audit PDFs, those should also have an S3 pointer (storage_path)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15be445",
   "metadata": {},
   "source": [
    "cascade behavior:    \n",
    "If an export log is deleted, should the join rows in exported_file also be deleted?    \n",
    "Usually yes → add cascade=\"all, delete-orphan\" on ExportedFile if you model it as a class.    \n",
    "If you keep exported_file as a raw Table, SQLAlchemy will handle cleanup when ExportLog is deleted.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1cbed3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportLog(Base, TimestampMixin):\n",
    "    __tablename__ = \"export_log\"\n",
    "\n",
    "    export_id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    project_id = Column(Integer, ForeignKey(\"project.project_id\"), nullable=False)\n",
    "    requested_by = Column(Integer, ForeignKey(\"user.user_id\"), nullable=False)\n",
    "\n",
    "    # Where the final package (ZIP, PDF, TAR, etc.) lives in S3/MinIO\n",
    "    storage_path = Column(String, nullable=False)\n",
    "\n",
    "    # Optional metadata\n",
    "    checksum = Column(String, nullable=True)\n",
    "    #included_file_ids = Column(JSON, nullable=True)  # list of files packaged\n",
    "    #included_versions = Column(JSON, nullable=True)  # if version-level tracking matters\n",
    "\n",
    "    status = Column(Enum(\"pending\", \"completed\", \"failed\", name=\"export_status_enum\"), default=\"pending\")\n",
    "\n",
    "    date_requested = Column(DateTime, default=func.now(), nullable=False)\n",
    "    date_completed = Column(DateTime, nullable=True)\n",
    "\n",
    "    # Relationships\n",
    "    project = relationship(\"Project\", back_populates=\"exports\")\n",
    "    requested_user = relationship(\"User\", foreign_keys=[requested_by])\n",
    "    file_versions = relationship(\n",
    "    \"FileVersion\",\n",
    "    secondary=\"exported_file\",    # uses the join table\n",
    "    back_populates=\"exports\"\n",
    "    )\n",
    "    exported_files = relationship(\n",
    "        \"ExportedFile\",\n",
    "        back_populates=\"export\",\n",
    "        cascade=\"all, delete-orphan\"\n",
    "    ) # Keep cascade — join table cleanup make sense here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1099d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import event, inspect\n",
    "\n",
    "def skip_updated_at(mapper, connection, target):\n",
    "    state = inspect(target)\n",
    "    model_name = target.__tablename__\n",
    "    real_cols = REAL_UPDATE_COLS.get(model_name, set())\n",
    "    if real_cols and not any(state.attrs[c].history.has_changes() for c in real_cols):\n",
    "        # none of the \"real\" columns changed → keep old updated_at\n",
    "        target.updated_at = state.attrs[\"updated_at\"].loaded_value\n",
    "\n",
    "# attach to all models where needed\n",
    "for model in [Project, File, FileVersion, User, AnnotationJob,\n",
    "              Assignment, Review, ExportLog, Organization]:\n",
    "    event.listen(model, \"before_update\", skip_updated_at)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MyProject Env)",
   "language": "python",
   "name": "myproject_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
